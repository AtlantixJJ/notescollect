#

## 提纲

1. MPI

2. PThread

3. OpenMP

4. Shared memory / distributed memory

## Chapter 1

### 并行的种类

1. Task Parallelism: 为了解决一个问题，将不同问题并行解决。

在加法并行中：每一次的局部加法是data，最终加起来是task.

2. Data Parallelism: 每个核进行相似的操作，但是数据是不同的。

### 其他术语

1. Concurrent computing: 多个任务可以同时进行（OS）。

2. Parallel computing： 多个任务同时紧密合作完成一个任务。

3. Distributed computing：一个程序与别的程序合作完成一个任务。

## Chapter 2

### Cache


## Chapter 3: MPI

MPI是一个distrubuted memory并行化方法。

他是Single Program Multiple Data。他只有一个程序，使用if-else结构来完成multiple data。

他定一个一个通讯群体：MPI_Comm_World。

然后调用MPI_Init完成初始化，调用MPI_Finalize结束并行化。在这两者之外的代码是不能使用MPI接口的。

### P2P通讯

使用MPI_Send和MPI_Recv进行阻塞式通讯。Send需要给出目的编号和tag。Recv需要给出来源编号和tag，tag对不上是不能接受的。也可以使用wildcard标签。

#### 三角积分规则

每一个子进程计算自己的结果，然后再加起来。

子进程是Send，根进程Recv。用for挨个接受就可以了。

### 集群通讯

MPI_Reduce：支持各种规则。输入是各个数组，输出是一个数。

注意Reduce的输入输出数组不能是同一个。

MPI_AllReduce：结果分布到所有进程中。实现方法可能是一个蝴蝶结构的计算树。

MPI_Bcast：单个节点的数据分布到所有节点中。

数据分配方法：

1. Block Partition

一个进程分配的数据形成一个周期。

2. Cyclic partition

进程之间分配的数据形成一个周期。

3. Block-cyclic partition

以块为单位在进程之间形成周期。

MPI_Scatter：将必要的数据发出去。

如果数据数量不是能够被进程数量等分，那么应该使用MPI_Scatterv。

MPI_Gather：将所有的component收集到根进程。

