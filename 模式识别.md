## 贝叶斯基础

### 贝叶斯公式

1. 先验概率$P(\omega_i)$，表示一个类别$\omega_i$的出现频率。在一个数据集中，可以统计得到。

2. 证据x是通过观察得到的特征，可以表示为向量的形式，也可以是一个表量。

3. 似然likelihood是$P(x|\omega_i)$，是一个类别内部特征x的分布。可以在一个数据集中统计得到。

4. 后验概率$P(\omega_i|x)$：观察到了证据x以后，先验概率可以转变成后验概率，表示该证据属于$\omega_i$的概率。

5. 贝叶斯公式：通过似然（以及先验概率、证据概率）得出后验概率的共识。

### 贝叶斯决策

#### 后验概率大小决策

1. 给定一个证据以后，可以得到属于每一类别的可能，所以可以进行比较。

2. 错误概率（注意不是损失）：其他所有类别的概率的加和。

3. 选择最大的后验概率进行决策`等于`选择最小化错误概率进行决策。

#### 推广决策

x是一个特征向量；$\omega_i$是类别；$\alpha_i$是行为。

引入损失函数（condition risk)：$R(\alpha_i | x) = \sum \lambda(\alpha_i|\omega_i) p(\omega_i|x)$，这是说在观察的证据x的情况下采取$\alpha_i$行为的损失，可以分解为每一个不同的类别下采用$\alpha_i$的损失。

1. 决策方法：在所有行为中选取最小的条件损失。

2. 最优决策定理：一个似然大于另一个似然的时候就可以做决定，进而可以用他们的比值做决定。通过换位可以推出表达式。

3. 最小错误率分类：行为就是选定一个类别。按照最优决策定理进行思考，这个比值所应该超过的阈值由损失矩阵决定。



贝叶斯模式识别流程：

1. 一个数据集，用$\{(x_i, y_i)\}$表示特征向量和类别。

2. 通过统计或者学习建模$P(x | y)$。对于简单的情况，就是统计$y = y_i$的类别下，$x_i$的分布情况。这实际上是表格函数，进行进一步建模，就是学习一个模型和它的向量$\theta$。

以高斯模型为例，建模是$P(x | y = y_i) = \mathcal{N}(x; \mu_i, \Sigma_i)$，表示用多维高斯分布表示第i类的特征分布情况。

进行学习（如果是统计分布则不需要）：

* Maximum Likelihood Estimation (MLE). 所谓似然就是给定一个模型（产生式模型），在数据集上的概率。 $\theta = argmax \Pi p( x_i | \theta, y_i) = argmax \Sigma log p( x_i | \theta, y_i)$。得到参数的方式：$\$

## 贝叶斯参数估计



## Nonparametric method

### Parzen Window

1. 简单的例子：二维平面内有一系列点（由一个未知分布产生），我们要估计这个分布。那么可以对每一个点赋予一个分布函数（例如高斯分布），将所有的分布加起来就是这个分布。

2. 正式定义：在一个d维度的空间里，定义一个函数$\phi(u)$，

Bayesian Decision: 一次、二次线性

优点：可以解决样本少的情况下的学习